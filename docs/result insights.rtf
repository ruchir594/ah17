{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf810
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Bold;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red0\green0\blue0;
\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;\csgenericrgb\c0\c0\c0;
\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 Result of Classifier
\b0  \
\
Naive Bayes classifier\'92s accuracy of 0.77 seemed good enough but trying SVMs, MLP, and Adaboost performed much better. KNN performed badly. So did Random Forest. It made sense that on this kind of Sparse data, Random Forest wouldn\'92t work. I didn\'92t even try decision tree classifier. \
\
The top 4 performing algorithms \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\b\fs22 \cf2 \cb3 \CocoaLigature0 1.1 Linear SVM
\f2\b0 \
\
Performance \
2819\
tp  1509\
tn  893\
fp  206\
fn  211\
accuracy  0.852075203973\
F1  0.878602620087\
precision 0.879883381924\
recall  0.877325581395\
\

\f1\b 1.2 Non Linear SVM (Radial Basis Function)
\f2\b0 \
\
Performance\
2819\
tp  1616\
tn  799\
fp  300\
fn  104\
accuracy  0.856686768358\
F1  0.888888888889\
precision 0.843423799582\
recall  0.939534883721\
\

\f1\b 1.3 MLP Classifier
\f2\b0 \
\
Performance \
2819\
tp  1548\
tn  808\
fp  291\
fn  172\
accuracy  0.835757360766\
F1  0.869907277325\
precision 0.84176182708\
recall  0.9\
\

\f1\b 1.4 Adaboost
\f2\b0 \
\
Performance\
2819\
tp  1487\
tn  865\
fp  234\
fn  233\
accuracy  0.834338417879\
F1  0.864283638477\
precision 0.864032539221\
recall  0.864534883721\
\
Non Linear SVM performed very well with accuracy of 0.85668\
But Ensembling these 4 with a simple voting scheme outperformed all 4. \
\
In our X_test of 2819\
tp  1526\
tn  893\
fp  206\
fn  194\
accuracy  0.858105711245\
F1  0.884125144844\
precision 0.881062355658\
recall  0.887209302326\
\
More importantly, notice Precision and Recall figures.\
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb5 \expnd0\expndtw0\kerning0
\CocoaLigature1 Precision: out of all the examples the classifier labeled as positive, what fraction were correct? \
Recall: out of all the positive examples there were, what fraction did the classifier got right?\
\
Ensemble has very balanced Precision and Recall figures. And with my final result, I would go with a balanced result. That\'92s what I have submitted to eval_predict_ens.tsv\
\

\f1\b Result of Parser
\f2\b0 \
\
Parser\'92s result were measured heuristically. We found a set of substructure in Parse tree which were reminder text from message text. We encoded that recursively, and it worked well on a handful of test data. \
\
However, some message text are structured poorly. Has grammatical errors, or Hinglish, or spelling mistakes. For such strings, we have a brute force function which is used as \'93last resort\'94 before we give in to \'93Not Found\'94. One way to improve upon such a result would be\
1. Run autocorrect on words\
2. Run autocorrect on sentence \
Before we parse it. Which will result in much better and consistent parsing.\
\
}